{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import des modules\n",
   "id": "e99a8f1c4f4bd3b6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T08:48:30.331635Z",
     "start_time": "2025-10-02T08:48:30.325665Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, KFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "#Preprocess\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MultiLabelBinarizer, MinMaxScaler\n",
    "\n",
    "#Modèles\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Metriques\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:48:30.362203Z",
     "start_time": "2025-10-02T08:48:30.336699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fc = pd.read_csv('fc_after_feature_engineering.csv')\n",
    "print(fc.info())"
   ],
   "id": "ae9d3797053beb5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 39 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   a_quitte_l_entreprise                      1470 non-null   bool   \n",
      " 1   age                                        1470 non-null   float64\n",
      " 2   annee_experience_totale                    1470 non-null   int64  \n",
      " 3   annees_dans_l_entreprise                   1470 non-null   int64  \n",
      " 4   annees_dans_le_poste_actuel                1470 non-null   int64  \n",
      " 5   annees_depuis_la_derniere_promotion        1470 non-null   int64  \n",
      " 6   annes_sous_responsable_actuel              1470 non-null   int64  \n",
      " 7   augementation_salaire_precedente           1470 non-null   int64  \n",
      " 8   distance_domicile_travail                  1470 non-null   int64  \n",
      " 9   domaine_etude_Entrepreunariat              1470 non-null   float64\n",
      " 10  domaine_etude_Infra & Cloud                1470 non-null   float64\n",
      " 11  domaine_etude_Marketing                    1470 non-null   float64\n",
      " 12  domaine_etude_Ressources Humaines          1470 non-null   float64\n",
      " 13  domaine_etude_Transformation Digitale      1470 non-null   float64\n",
      " 14  frequence_deplacement                      1470 non-null   float64\n",
      " 15  genre                                      1470 non-null   bool   \n",
      " 16  heure_supplementaires                      1470 non-null   bool   \n",
      " 17  nb_formations_suivies                      1470 non-null   int64  \n",
      " 18  niveau_education                           1470 non-null   int64  \n",
      " 19  niveau_hierarchique_poste                  1470 non-null   int64  \n",
      " 20  nombre_experiences_precedentes             1470 non-null   int64  \n",
      " 21  nombre_participation_pee                   1470 non-null   int64  \n",
      " 22  note_evaluation_actuelle                   1470 non-null   int64  \n",
      " 23  note_evaluation_precedente                 1470 non-null   int64  \n",
      " 24  poste_Cadre Commercial                     1470 non-null   float64\n",
      " 25  poste_Consultant                           1470 non-null   float64\n",
      " 26  poste_Directeur Technique                  1470 non-null   float64\n",
      " 27  poste_Manager                              1470 non-null   float64\n",
      " 28  poste_Representant Commercial              1470 non-null   float64\n",
      " 29  poste_Ressources Humaines                  1470 non-null   float64\n",
      " 30  poste_Senior Manager                       1470 non-null   float64\n",
      " 31  poste_Tech Lead                            1470 non-null   float64\n",
      " 32  revenu_mensuel                             1470 non-null   float64\n",
      " 33  satisfaction_employee_environnement        1470 non-null   int64  \n",
      " 34  satisfaction_employee_equilibre_pro_perso  1470 non-null   int64  \n",
      " 35  satisfaction_employee_equipe               1470 non-null   int64  \n",
      " 36  satisfaction_employee_nature_travail       1470 non-null   int64  \n",
      " 37  satisfaction_globale                       1470 non-null   float64\n",
      " 38  statut_marital                             1470 non-null   float64\n",
      "dtypes: bool(3), float64(18), int64(18)\n",
      "memory usage: 417.9 KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Séparation train test simple\n",
    "- Des métriques d’évaluation calculées pour chaque modèle, sur le jeu d’apprentissage et le jeu de test."
   ],
   "id": "ab005bc0df6f5796"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:48:30.372936Z",
     "start_time": "2025-10-02T08:48:30.364840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns_base = ['age', 'annees_dans_l_entreprise', 'distance_domicile_travail', 'genre', 'heure_supplementaires','satisfaction_globale','statut_marital','revenu_mensuel']\n",
    "columns_domaine_etude = [col for col in fc.columns if col.startswith('domaine_etude')]\n",
    "columns_poste = [col for col in fc.columns if col.startswith('poste')]\n",
    "\n",
    "all_columns = columns_base + columns_domaine_etude + columns_poste\n",
    "\n",
    "X = fc[all_columns]\n",
    "y = fc['a_quitte_l_entreprise']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=666)"
   ],
   "id": "9f209612188d56f5",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Validation croisée simple\n",
    "- cross_validate"
   ],
   "id": "6f174397daf9030d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:48:30.378895Z",
     "start_time": "2025-10-02T08:48:30.375742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def perform_cross_validation(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    model,\n",
    "    cross_val_type, # La variante de validation croisée que nous souhaitons utiliser\n",
    "    scoring_metrics: tuple, # Metriques de notre choix\n",
    "    return_estimator=False, # Si nous souhaitons stocker les modèles de chaque fold\n",
    "    groups=None, # Nous verrons l’utilité de cet argument juste après\n",
    "):\n",
    "    scores = cross_validate(\n",
    "        model,\n",
    "        X.to_numpy(),\n",
    "        y.to_numpy(),\n",
    "        cv=cross_val_type,\n",
    "        return_train_score=True,\n",
    "        return_estimator=return_estimator,\n",
    "        scoring=scoring_metrics,\n",
    "        groups=groups,\n",
    "    )\n",
    "\n",
    "    for metric in scoring_metrics:\n",
    "        # la moyenne des scores (performance moyenne du modèle)\n",
    "        print(\n",
    "            \"{metric} Train Average : {metric_value}\".format(\n",
    "                metric=metric,\n",
    "                metric_value=round(np.mean(scores[\"train_\" + metric]),2),\n",
    "            )\n",
    "        )\n",
    "        # la standard deviation des scores (stabilité/variance du modèle)\n",
    "        print(\n",
    "            \"{metric} Train Standard Deviation : {metric_value}\".format(\n",
    "                metric=metric, metric_value=round(np.std(scores[\"train_\" + metric]),2)\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"{metric} Test Average : {metric_value}\".format(\n",
    "                metric=metric, metric_value=round(np.mean(scores[\"test_\" + metric]),2)\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"{metric} Test Standard Deviation : {metric_value}\".format(\n",
    "                metric=metric, metric_value=round(np.std(scores[\"test_\" + metric]),2)\n",
    "            )\n",
    "        )\n",
    "        print(\"------\")\n",
    "\n",
    "    return scores"
   ],
   "id": "b1443a7a9f5add6b",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fonctions",
   "id": "18cf6638fe6c883b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:48:30.383250Z",
     "start_time": "2025-10-02T08:48:30.381063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "list_model = []\n",
    "\n",
    "def perform_model_class(model_name, model, X_train, y_train, X_test, y_test):\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        #F1-score : compromis entre précision et rappel.\n",
    "        #average=\"macro\" : moyenne simple entre classes (équilibre toutes les classes, même si elles sont rares).\n",
    "        #average=\"weighted\" : pondérée par le nombre d’exemples par classe.\n",
    "        #average=\"micro\" : global (utilise les VP/FP/FN de toutes les classes confondues).\n",
    "\n",
    "        model_results = {\n",
    "                'Model': model_name,\n",
    "                'Accuracy': accuracy,\n",
    "                'F1': f1\n",
    "            }\n",
    "\n",
    "        # Matrice de confusion\n",
    "        print(\"Matrice de confusion :\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        # Rapport complet (precision, recall, f1, support)\n",
    "        print(\"\\nRapport de classification :\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        list_model.append(model_results)"
   ],
   "id": "42b712baf50c2528",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Modele DUMMY\n",
    "- DummyClassifier"
   ],
   "id": "650ed83dcec2372b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:48:30.408442Z",
     "start_time": "2025-10-02T08:48:30.386621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dummy Regressor (baseline)\n",
    "print('############### MODELE DummyClassifier ################\\n')\n",
    "model_name = 'DummyClassifier'\n",
    "model = DummyClassifier(strategy=\"most_frequent\")\n",
    "perform_model_class(model_name, model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(list_model)\n",
    "\n",
    "###################################\n",
    "\n",
    "classification_scoring_metrics = (\"accuracy\", \"f1_macro\")\n",
    "\n",
    "scores_DummyClassifier = perform_cross_validation(\n",
    "        X=X,\n",
    "        y=y,\n",
    "        model=DummyClassifier(),\n",
    "        cross_val_type=KFold(n_splits=5, shuffle=True, random_state=666), #Par défaut, le nombre de folds est 5\n",
    "        scoring_metrics=classification_scoring_metrics,\n",
    "    )\n",
    "\n"
   ],
   "id": "2d604602110c3c25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### MODELE DummyClassifier ################\n",
      "\n",
      "Matrice de confusion :\n",
      "[[252   0]\n",
      " [ 42   0]]\n",
      "\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      1.00      0.92       252\n",
      "        True       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.73      0.86      0.79       294\n",
      "\n",
      "[{'Model': 'DummyClassifier', 'Accuracy': 0.8571428571428571, 'F1': 0.46153846153846156}]\n",
      "accuracy Train Average : 0.84\n",
      "accuracy Train Standard Deviation : 0.0\n",
      "accuracy Test Average : 0.84\n",
      "accuracy Test Standard Deviation : 0.02\n",
      "------\n",
      "f1_macro Train Average : 0.46\n",
      "f1_macro Train Standard Deviation : 0.0\n",
      "f1_macro Test Average : 0.46\n",
      "f1_macro Test Standard Deviation : 0.01\n",
      "------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tico/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/tico/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/tico/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " # Modele LINEAIRE",
   "id": "f70bdcb11e6d8d8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:48:30.417695Z",
     "start_time": "2025-10-02T08:48:30.416524Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "29a0efd29823ea6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Modele NON LINEAIRE\n",
    "- RandomForest, XGBoost ou CatBoost\n",
    "- Métriques d’évaluation en classification : matrice de confusion, rappel et précision.\n",
    "- Scores (présence d’overfit ou non, capacité d’éviter les faux positifs ou faux négatifs)"
   ],
   "id": "cdbcdda4b8fc0779"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:48:30.420586Z",
     "start_time": "2025-10-02T08:48:30.419542Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "71893e88c443dd4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Amélioration de la classification\n",
    "- demandez-vous si éviter des faux positifs est plus important qu’éviter des faux négatifs."
   ],
   "id": "fcd52f7d66ce3752"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:48:30.423091Z",
     "start_time": "2025-10-02T08:48:30.422031Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6a0ef8be5672fd39",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
